{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vanillanet import *\n",
    "import time\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import subprocess\n",
    "from argparse import Namespace\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    stdout: str = ''\n",
    "    stderr: str = ''\n",
    "    avg_latency: float = 0.\n",
    "    throughput: float = 0.\n",
    "\n",
    "\n",
    "def run_benchmark(cmd):\n",
    "    with subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as p:\n",
    "        p.wait()\n",
    "        stdout = p.stdout.read().decode()\n",
    "        stderr = p.stderr.read().decode()\n",
    "        # print(stdout)\n",
    "        # print(stderr)\n",
    "        stdout = stdout.strip()\n",
    "        avg_line = filter(None, stdout.split('\\n')[-4].split())\n",
    "        throughput_line = filter(None, stdout.split('\\n')[-1].split())\n",
    "        avg_line = list(avg_line)\n",
    "        throughput_line = list(throughput_line)\n",
    "        assert 'Average:' in avg_line and 'Throughput:' in throughput_line\n",
    "\n",
    "        return BenchmarkResult(\n",
    "            stdout=stdout,\n",
    "            stderr=stderr,\n",
    "            avg_latency=float(list(avg_line)[-2]),\n",
    "            throughput=float(list(throughput_line)[-2]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_cls) -> torch.nn.Module:\n",
    "    net = model_cls().cuda()\n",
    "    net.eval()\n",
    "    net.switch_to_deploy()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(net, name_str):\n",
    "    result = {}\n",
    "    img = torch.rand((1, 3, 224, 224))\n",
    "\n",
    "    # latency\n",
    "    net = net.eval()\n",
    "    img = img.cuda()\n",
    "    net = net.cuda()\n",
    "    with torch.no_grad():\n",
    "        for i in range(50):\n",
    "            net(img)\n",
    "        torch.cuda.synchronize()\n",
    "        t = time.time()\n",
    "        for i in range(1000):\n",
    "            net(img)\n",
    "            torch.cuda.synchronize()\n",
    "    result['latency_cuda_torch'] = (time.time() - t)\n",
    "\n",
    "    # torch output\n",
    "    with torch.no_grad():\n",
    "        torch_output = net(img)\n",
    "        if not isinstance(torch_output, torch.Tensor):\n",
    "            torch_output = torch_output.logits\n",
    "        torch_output = torch_output.cpu().view(-1)\n",
    "\n",
    "    onnx_path = f\"/tmp/yujiepan/{name_str}.onnx\"\n",
    "    model = net.eval().cpu()\n",
    "    torch.onnx.export(model,\n",
    "                      img.cpu(),\n",
    "                      onnx_path,\n",
    "                      verbose=False,\n",
    "                      opset_version=13,\n",
    "                      do_constant_folding=True,\n",
    "    )\n",
    "    \n",
    "    onnx_model = onnx.load_model(onnx_path)\n",
    "    sess = ort.InferenceSession(onnx_model.SerializeToString())\n",
    "    sess.set_providers(['CPUExecutionProvider'])\n",
    "    # sess.set_providers(['CUDAExecutionProvider'])\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    output_name = sess.get_outputs()[0].name\n",
    "    output = sess.run([output_name], {input_name : img.cpu().numpy()})\n",
    "    onnx_output = torch.tensor(output).view(-1)\n",
    "    torch.testing.assert_close(onnx_output, torch_output, atol=1e-4, rtol=1e-4)\n",
    "\n",
    "    result['latency'] = run_benchmark(cmd=f'benchmark_app -m {onnx_path} -niter 2000 -hint latency').avg_latency\n",
    "    result['throughput'] = run_benchmark(cmd=f'benchmark_app -m {onnx_path} -hint throughput -t 35').throughput\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, SwinForImageClassification\n",
    "import torchvision\n",
    "import repvgg\n",
    "import pandas as pd\n",
    "\n",
    "all_results = []\n",
    "for model, name_str in [\n",
    "    (torchvision.models.mobilenet_v3_large(), 'mobilenet_v3_large'),\n",
    "    (SwinForImageClassification.from_pretrained('microsoft/swin-tiny-patch4-window7-224'), 'swin_t'),\n",
    "    (SwinForImageClassification.from_pretrained('microsoft/swin-small-patch4-window7-224'), 'swin_s'),\n",
    "    (repvgg.create_RepVGG_B3(deploy=True), 'create_RepVGG_B3'),\n",
    "    (torchvision.models.resnet50(), 'resnet50'),\n",
    "    (get_model(vanillanet_9), 'vanillanet_9'),\n",
    "    (get_model(vanillanet_12), 'vanillanet_12'),\n",
    "    (get_model(vanillanet_13_x1_5_ada_pool), 'vanillanet_13_x1_5_ada_pool'),\n",
    "]:\n",
    "    result = job(model, name_str)\n",
    "    result['name'] = name_str\n",
    "    all_results.append(result)\n",
    "    pd.DataFrame(all_results).to_csv('result.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
